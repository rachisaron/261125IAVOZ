¬°Listo! Aqu√≠ tienes un **PROMPT MAESTRO** para que *otra IA* construya el proyecto completo exactamente como lo definimos (con la misma arquitectura, endpoints, separaci√≥n l√≥gica/dise√±o, modelos y dise√±o de la tarjeta de correcci√≥n). Solo c√≥pialo y p√©galo en la otra IA.

---

# PROMPT MAESTRO ‚Äî ‚ÄúProfe ELE ‚Äì IA Voz‚Äù (Replit, producci√≥n m√≠nima viable)

## Rol

Eres un(a) **experto(a) full-stack** y **arquitecto(a) de IA conversacional**. Debes **entregar un proyecto completo y listo para ejecutar en Replit** que implemente un **widget web** llamado:

> **Profe ELE ‚Äì IA Voz**

El widget permite hablar en espa√±ol por micr√≥fono, responde con **OpenAI Realtime (WebRTC)** por voz, muestra **tarjetas visuales de correcci√≥n** alimentadas por un **or√°culo REST con `gpt-5-mini`**, y transcribe el hablante (alumno) a texto limpio usando **`gpt-4o-transcribe`** para mostrarlo en la UI.

## Reglas clave (obligatorias)

1. **Modelos**

   * Conversaci√≥n y voz: `gpt-realtime` con voz expresiva moderna (por defecto `"verse"`).
   * Or√°culo de gram√°tica (REST): `gpt-5-mini`.
   * Transcripci√≥n UI: `gpt-4o-transcribe` (Audio/Transcriptions).
2. **Prompts en disco (no hard-code)**

   * `prompts/realtime-prompt.md` (instrucciones del maestro ELE Realtime).
   * `prompts/grammar-oracle-prompt.md` (instrucciones del or√°culo, salida **solo JSON**).
   * El backend **lee estos archivos**; cambiar el prompt **no** requiere tocar c√≥digo.
3. **Separaci√≥n estricta de l√≥gica y dise√±o**

   * **Core (l√≥gica):** WebRTC, colas, llamadas REST, sin tocar DOM/CSS.
   * **UI:** DOM, eventos, render y todo el **dise√±o** en HTML/CSS.
   * Cambiar dise√±o **no debe** requerir tocar el core.

## Stack y estructura

* **Backend:** Node.js 20 + Express.
* **Frontend:** HTML + CSS + vanilla JS.
* **OpenAI SDK v4**.
* **Replit**: instala Node 20, configura runner, y expone puerto 3000 ‚áí 80.

**√Årbol de archivos (exacto):**

```
.replit
replit.md
package.json
backend/
  server.js
  services/
    realtimeSession.js
    grammarOracle.js
    transcriber.js
frontend/
  index.html
  ia-voz-core.js
  ia-voz-ui.js
  ia-voz.css
prompts/
  realtime-prompt.md
  grammar-oracle-prompt.md
```

## Endpoints backend (contratos)

* `GET /config` ‚Üí JSON:

  ```json
  {
    "realtimeModel": "gpt-realtime",
    "realtimeVoice": "verse",
    "grammarModel": "gpt-5-mini",
    "transcribeModel": "gpt-4o-transcribe",
    "correctionsEnabled": true,
    "readCorrectionsAloud": true
  }
  ```
* `POST /session`

  * Lee `prompts/realtime-prompt.md`.
  * Crea **Realtime session** (`/v1/realtime/sessions`) con `{ model, voice, instructions }`.
  * Devuelve `{ client_secret }` ef√≠mero.
* `POST /correct`

  * Body: `{ "text": "<oraci√≥n del alumno>" }`
  * Llama a `gpt-5-mini` con **system** = `prompts/grammar-oracle-prompt.md`.
  * **Debe devolver solo**:

    ```json
    {
      "is_error": boolean,
      "error": "original sentence",
      "fix": "corrected sentence",
      "reason": "short Spanish reason (max 8-10 words)"
    }
    ```
  * Si hay duda: `is_error=false`, `fix=original`, `reason="Est√° bien dicho."`.
* `POST /transcribe`

  * Recibe audio (multipart, un solo enunciado).
  * Llama `gpt-4o-transcribe` (Audio/Transcriptions) con `language=es`.
  * Devuelve `{ "transcript": "<texto limpio>" }`.

## L√≥gica del frontend (archivo core, **sin DOM**)

**`frontend/ia-voz-core.js`**:

* Gestiona WebRTC + Realtime (RTCPeerConnection, DataChannel, mic).
* **Estado:**

  * `connected`, `assistantSpeaking`, `studentSpeaking`
  * `pendingCorrections` (cola)
  * `lastUserTranscript`
* **Callbacks inyectadas por UI:**

  * `onStatusChange(status)`
  * `onUserTranscript(text)`
  * `onAssistantMessage(text)`
  * `onCorrectionCard(correctionObj)`
  * `onAudioStream(stream)`
  * `onTalking(isTalking)`
* **Flujo:**

  1. Al pulsar mic: crea Realtime session (`/session`), negocia SDP con `POST /v1/realtime?model=...` usando el `client_secret` como Bearer.
  2. Usa eventos VAD del servidor (`speech_started`/`speech_stopped`) para marcar `studentSpeaking`.
  3. Graba buffer local por utterance; al parar:

     * `POST /transcribe` ‚Üí `{ transcript }` ‚Üí `onUserTranscript`.
     * `POST /correct` con el transcript.
  4. El Realtime responde por voz y emite texto por data channel ‚Üí `onAssistantMessage`.
* **Cola de correcciones**:

  * Si `is_error=true`, encola `{ error, fix, reason, createdAt, turnIndex }`, llama `onCorrectionCard` **de inmediato**, y luego **trySpeakNextCorrection()**.
  * **trySpeakNextCorrection():** solo habla si `connected` y no hay `assistantSpeaking` ni `studentSpeaking`.
  * Mensaje que se env√≠a al Realtime (para que lea **una l√≠nea breve**):

    ```
    [CORRECCION]
    ERROR: "..."
    FIX: "..."
    REASON: "..."
    ```
  * Si el alumno empieza a hablar, no se env√≠an nuevas correcciones; la cola **no se pierde**.

## UI (archivo de integraci√≥n con DOM) y dise√±o

**`frontend/ia-voz-ui.js`**:

* Renderiza dentro de `#ia-voz`:

  * **Header** con t√≠tulo ‚ÄúProfe ELE ‚Äì IA Voz‚Äù, punto de estado (gris ‚Üí verde) y bot√≥n ‚öôÔ∏è.
  * **Chat scrollable** con bubble inicial del asistente (‚ÄúHola, soy tu profesor virtual. ¬°Hablemos!‚Äù).
  * **Footer** con input de texto opcional y **bot√≥n de mic** circular con ondas.
  * `<audio autoplay>` para stream remoto.
* Crea instancia del core y pasa callbacks:

  * `onAudioStream` ‚Üí asigna `srcObject`.
  * `onAssistantMessage`/`onUserTranscript` ‚Üí a√±ade bubbles.
  * `onCorrectionCard` ‚Üí **renderiza tarjeta exacta**.
  * `onTalking` ‚Üí activa/desactiva ondas del mic.
* **Eventos:**

  * Click mic ‚Üí `core.toggleConnection()`.
  * Enviar texto ‚Üí `core.sendText(text)` (opcional).

**`frontend/ia-voz.css`** (todo el estilo aqu√≠):

* **Widget** (card 380√ó680 aprox.), fondo gris muy claro, border-radius 24px, sombra `0 18px 45px rgba(0,0,0,.12)`.
* **Header**

  * Alto ~56px, fondo **azul marino** `#182539`, t√≠tulo blanco 600‚Äì700, punto de estado gris ‚Üí verde `#3CC47C`, bot√≥n ‚öôÔ∏è ghost.
* **Chat**

  * Fondo `#F6F7F9`, overflow-y, bubbles:

    * Asistente: izquierda, **mostaza** `#F1C75B`, sombra suave.
    * Usuario: derecha, blanco con borde `#E0E0E0`.
* **Mic**

  * Bot√≥n circular terracota `--ia-mic = #E25A2C`, ondas conc√©ntricas animadas.
* **Tarjeta de correcci√≥n** (clases exactas):

  * `.iav-correction-card` contenedor blanco con sombra `0 6px 16px rgba(0,0,0,.12)`, radio 12px, **franja vertical a la izquierda** del mismo color del mic (`--ia-mic`), 6‚Äì8px de ancho.
  * T√≠tulo **‚ÄúCorrection‚Äù** (12px, #444, 600).
  * Filas:

    * Error: icono rojo `‚úï` `#C7442E`, **‚ÄúDijiste:‚Äù** en negrita, texto con **subrayado** y color rojo.
    * Fix: icono verde `‚úî` `#1A7C4A`, **‚ÄúMejor di:‚Äù** en negrita, texto con **subrayado** y color verde.
    * Raz√≥n: icono `üí°`, **‚ÄúPor qu√©:‚Äù** en negrita, texto en *cursiva* gris medio `#555`.
  * Margen vertical 8‚Äì12px, gap entre filas 4‚Äì6px.

## Contenido de prompts (archivos en `/prompts`)

* **`realtime-prompt.md` (ES):**

  * Rol **Profe ELE** A2‚ÄìB2, respuestas breves y naturales.
  * **Nunca corrige por s√≠ mismo**; solo cuando recibe el bloque `[CORRECCION]`.
  * Ante un bloque v√°lido y cuando pueda hablar, dice **una sola l√≠nea breve**:

    * ¬´Por cierto, no se dice "ERROR", se dice "FIX", porque REASON.¬ª
      **o**
      ¬´Antes de seguir, sobre lo que dijiste antes: no se dice "ERROR", se dice "FIX", porque REASON.¬ª
  * Luego contin√∫a con una pregunta breve relacionada.
* **`grammar-oracle-prompt.md`:**

  * Devuelve **solo JSON**:

    ```json
    {"is_error": boolean, "error": "...", "fix": "...", "reason": "..."}
    ```
  * Pol√≠tica conservadora: si hay duda, `is_error=false`, `reason="Est√° bien dicho."`.
  * ‚Äúreason‚Äù muy corta (8‚Äì10 palabras).

## Implementaci√≥n por archivos (resumen)

* **`.replit`**: instala Node 20, corre `npm ci` y `npm run dev`, mapea puerto 3000‚Üí80.
* **`replit.md`**: instrucciones para a√±adir `OPENAI_API_KEY` y ejecutar.
* **`package.json`**: dependencias `express`, `cors`, `multer`, `dotenv`, `openai@^4`, `nodemon`.
* **`backend/server.js`**:

  * `GET /config`, `POST /session`, `POST /correct`, `POST /transcribe`.
  * Sirve `frontend/` como est√°tico; fallback a `index.html`.
* **`backend/services/realtimeSession.js`**:

  * `createRealtimeEphemeral({ model, voice, instructions })` ‚Üí `POST https://api.openai.com/v1/realtime/sessions` con API key del backend ‚Üí retorna `{ client_secret }`.
* **`backend/services/grammarOracle.js`**:

  * Usa OpenAI Responses con `response_format: json_schema` y esquema estricto.
  * Lee `prompts/grammar-oracle-prompt.md`.
* **`backend/services/transcriber.js`**:

  * `POST /v1/audio/transcriptions` con `model=gpt-4o-transcribe`, `language=es`.
* **`frontend/index.html`**:

  * Contenedor `#ia-voz`, incluye `ia-voz.css`, `ia-voz-core.js`, `ia-voz-ui.js`.
* **`frontend/ia-voz-core.js`**:

  * **No DOM**, toda la l√≥gica descrita, callbacks.
* **`frontend/ia-voz-ui.js`**:

  * Construye DOM, gestiona eventos, mapea callbacks a render.
* **`frontend/ia-voz.css`**:

  * Todo el estilo (variables, layout, bubbles, mic ripple, **tarjeta de correcci√≥n exacta**).

## Entregables (formato de salida)

Devuelve **todos los archivos completos** en un solo mensaje, con este formato por archivo:

```
--- path: <RUTA/DEL/ARCHIVO> ---
```

<contenido exacto del archivo, completo>

````
```

**Ejemplo:**
```
--- path: package.json ---
```json
{ ...contenido... }
```
```

No devuelvas diffs; **siempre** archivos completos y listos para copiar/pegar.

## Variables de entorno
- `OPENAI_API_KEY` (definida en Replit Secrets). **Nunca** la expongas al frontend.
- El frontend usa `/session` para recibir un **token ef√≠mero** Realtime.

## Criterios de aceptaci√≥n (QA)
- Al pulsar üé§:
  - Se conecta (punto verde en header), se oyen respuestas por voz.
  - Cuando el alumno deja de hablar, aparece el **texto transcrito limpio**.
  - Llega **tarjeta de correcci√≥n** (aunque no haya error, con ‚ÄúEst√° bien dicho.‚Äù).
  - Si hay error, el profe **lee una sola l√≠nea** de correcci√≥n cuando no interrumpe al alumno ni a s√≠ mismo.
- El cambio de colores/tipograf√≠as o layout **solo** requiere tocar CSS/HTML/UI; el core no importa dise√±o.
- Cambiar la voz o prompt no requiere tocar el UI/core (solo `/config` o archivos en `/prompts`).

## Consideraciones adicionales
- Limita tama√±o de upload de audio a 25 MB.
- Manejo de errores conservador en `/correct` y `/transcribe`.
- Escapa HTML al renderizar texto del alumno/IA en la UI.
- Usa `MediaRecorder` con `audio/webm` y `echoCancellation/noiseSuppression`.

---

**Ahora, genera el proyecto exactamente con lo anterior y devuelve todos los archivos siguiendo el formato de ‚ÄúEntregables (formato de salida)‚Äù.**
````
